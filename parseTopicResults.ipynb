{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f15ac4-c675-44e1-8879-e1518ce81fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8430fadf-2d5d-4ce4-a368-1cfc8f53a19e",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96142ef2-ab86-4c9d-becb-d366b411c334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56609\n",
      "53349\n",
      "CPU times: user 7.55 s, sys: 1.99 s, total: 9.54 s\n",
      "Wall time: 24.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>newsOutlet</th>\n",
       "      <th>category</th>\n",
       "      <th>dateSeen</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>sourceCountry</th>\n",
       "      <th>sentText</th>\n",
       "      <th>sentIndexInText</th>\n",
       "      <th>sentTopicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>western</td>\n",
       "      <td>2021-10-12 07:00:00</td>\n",
       "      <td>https://apnews.com/article/technology-business...</td>\n",
       "      <td>EU , Ukraine to discuss military training and ...</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>BRUSSELS (AP) — The European Union is consider...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>western</td>\n",
       "      <td>2021-10-12 07:00:00</td>\n",
       "      <td>https://apnews.com/article/technology-business...</td>\n",
       "      <td>EU , Ukraine to discuss military training and ...</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>Acting on a request from Ukraine for help with...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>western</td>\n",
       "      <td>2021-10-12 07:00:00</td>\n",
       "      <td>https://apnews.com/article/technology-business...</td>\n",
       "      <td>EU , Ukraine to discuss military training and ...</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>The topic will be discussed during a summit Tu...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>western</td>\n",
       "      <td>2021-10-12 07:00:00</td>\n",
       "      <td>https://apnews.com/article/technology-business...</td>\n",
       "      <td>EU , Ukraine to discuss military training and ...</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>The results of the mission have yet to be anal...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>western</td>\n",
       "      <td>2021-10-12 07:00:00</td>\n",
       "      <td>https://apnews.com/article/technology-business...</td>\n",
       "      <td>EU , Ukraine to discuss military training and ...</td>\n",
       "      <td>English</td>\n",
       "      <td>United States</td>\n",
       "      <td>One official said the EU’s political and secur...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  newsOutlet category             dateSeen  \\\n",
       "0      0  apnews.com  western  2021-10-12 07:00:00   \n",
       "1      0  apnews.com  western  2021-10-12 07:00:00   \n",
       "2      0  apnews.com  western  2021-10-12 07:00:00   \n",
       "3      0  apnews.com  western  2021-10-12 07:00:00   \n",
       "4      0  apnews.com  western  2021-10-12 07:00:00   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://apnews.com/article/technology-business...   \n",
       "1  https://apnews.com/article/technology-business...   \n",
       "2  https://apnews.com/article/technology-business...   \n",
       "3  https://apnews.com/article/technology-business...   \n",
       "4  https://apnews.com/article/technology-business...   \n",
       "\n",
       "                                               title language  sourceCountry  \\\n",
       "0  EU , Ukraine to discuss military training and ...  English  United States   \n",
       "1  EU , Ukraine to discuss military training and ...  English  United States   \n",
       "2  EU , Ukraine to discuss military training and ...  English  United States   \n",
       "3  EU , Ukraine to discuss military training and ...  English  United States   \n",
       "4  EU , Ukraine to discuss military training and ...  English  United States   \n",
       "\n",
       "                                            sentText  sentIndexInText  \\\n",
       "0  BRUSSELS (AP) — The European Union is consider...                0   \n",
       "1  Acting on a request from Ukraine for help with...                1   \n",
       "2  The topic will be discussed during a summit Tu...                2   \n",
       "3  The results of the mission have yet to be anal...                3   \n",
       "4  One official said the EU’s political and secur...                4   \n",
       "\n",
       "   sentTopicID  \n",
       "0           -1  \n",
       "1           -1  \n",
       "2           -1  \n",
       "3            5  \n",
       "4           -1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sdf = pd.read_excel('data/topic_model_data/fullSentDataFrame_8-3.xlsx',index_col=0)\n",
    "print(len(sdf))\n",
    "sdf = sdf.drop_duplicates(['sentText'])\n",
    "print(len(sdf))\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7edc9bb0-a2b3-4260-b618-5f6da14d9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/paigelee/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/paigelee/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentiText\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e76dcb2-dafa-4001-9d17-b122caa91452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 22s, sys: 2.45 s, total: 4min 25s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# add sentiment row to DF\n",
    "sentiRecs = []\n",
    "records = sdf.to_dict('records')\n",
    "for rec in records:\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(rec['sentText'])\n",
    "    artSenti = dict()\n",
    "    for k in ['pos','neu','neg']:\n",
    "        artSenti[k] = ss[k]\n",
    "    sentiRecs.append(artSenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6ecf9b7-c32d-4e86-8a31-ed9ab4134e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>newsOutlet</th>\n",
       "      <th>category</th>\n",
       "      <th>dateSeen</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>sourceCountry</th>\n",
       "      <th>sentText</th>\n",
       "      <th>sentIndexInText</th>\n",
       "      <th>sentTopicID</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "      <th>sentiVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40770</th>\n",
       "      <td>1813.0</td>\n",
       "      <td>tass.com</td>\n",
       "      <td>russian</td>\n",
       "      <td>2022-01-21 08:00:00</td>\n",
       "      <td>https://tass.com/politics/1391611</td>\n",
       "      <td>European security issues shouldnt be limited t...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I am fairly certain that, one way or another, ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32731</th>\n",
       "      <td>1295.0</td>\n",
       "      <td>sputniknews.com</td>\n",
       "      <td>russian</td>\n",
       "      <td>2022-01-16 08:00:00</td>\n",
       "      <td>https://sputniknews.com/20220116/some-of-ameri...</td>\n",
       "      <td>Some of America NATO Allies Were  Unsettled  b...</td>\n",
       "      <td>English</td>\n",
       "      <td>Russia</td>\n",
       "      <td>The draft accords were presented to the US and...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23662</th>\n",
       "      <td>979.0</td>\n",
       "      <td>sputniknews.com</td>\n",
       "      <td>russian</td>\n",
       "      <td>2022-02-21 08:00:00</td>\n",
       "      <td>https://sputniknews.com/20220221/russia-recogn...</td>\n",
       "      <td>Russia Recognises Donbass Republic Independence</td>\n",
       "      <td>English</td>\n",
       "      <td>Russia</td>\n",
       "      <td>\"We have also heard statements about Ukraine t...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36254</th>\n",
       "      <td>1488.0</td>\n",
       "      <td>sputniknews.com</td>\n",
       "      <td>russian</td>\n",
       "      <td>2022-02-16 08:00:00</td>\n",
       "      <td>https://sputniknews.com/20220216/cheating-hunt...</td>\n",
       "      <td>New Book on US First Lady Jill May Cause Disco...</td>\n",
       "      <td>English</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Joe Biden has categorically denied the accusat...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index       newsOutlet category            dateSeen  \\\n",
       "40770  1813.0         tass.com  russian 2022-01-21 08:00:00   \n",
       "32731  1295.0  sputniknews.com  russian 2022-01-16 08:00:00   \n",
       "23662   979.0  sputniknews.com  russian 2022-02-21 08:00:00   \n",
       "36254  1488.0  sputniknews.com  russian 2022-02-16 08:00:00   \n",
       "\n",
       "                                                     url  \\\n",
       "40770                  https://tass.com/politics/1391611   \n",
       "32731  https://sputniknews.com/20220116/some-of-ameri...   \n",
       "23662  https://sputniknews.com/20220221/russia-recogn...   \n",
       "36254  https://sputniknews.com/20220216/cheating-hunt...   \n",
       "\n",
       "                                                   title language  \\\n",
       "40770  European security issues shouldnt be limited t...  English   \n",
       "32731  Some of America NATO Allies Were  Unsettled  b...  English   \n",
       "23662    Russia Recognises Donbass Republic Independence  English   \n",
       "36254  New Book on US First Lady Jill May Cause Disco...  English   \n",
       "\n",
       "      sourceCountry                                           sentText  \\\n",
       "40770           NaN  I am fairly certain that, one way or another, ...   \n",
       "32731        Russia  The draft accords were presented to the US and...   \n",
       "23662        Russia  \"We have also heard statements about Ukraine t...   \n",
       "36254        Russia  Joe Biden has categorically denied the accusat...   \n",
       "\n",
       "       sentIndexInText  sentTopicID    pos    neu    neg  sentiVal  \n",
       "40770              5.0         12.0  0.045  0.955  0.000     0.045  \n",
       "32731             15.0         -1.0  0.149  0.810  0.041     0.108  \n",
       "23662             19.0         12.0  0.000  0.726  0.274    -0.274  \n",
       "36254             16.0         -1.0  0.000  1.000  0.000     0.000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentOnlyDf = pd.DataFrame.from_records(sentiRecs)\n",
    "df = pd.concat([sdf, sentOnlyDf],axis=1)\n",
    "df['dateSeen'] = df['dateSeen'].apply(lambda d: pd.to_datetime(d))\n",
    "df['sentiVal'] = df['pos']-df['neg']\n",
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1e455-4618-4e34-880a-cce862b937b9",
   "metadata": {},
   "source": [
    "### Write JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "87ca0273-4cd3-4f7e-b329-ca5447db4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonDf = df.copy(deep=True)\n",
    "# jsonDf['dateSeen'] = jsonDf['dateSeen'].apply(lambda d : d.timestamp())\n",
    "# del jsonDf['month']\n",
    "# del jsonDf['sourceCountry']\n",
    "\n",
    "# with open('visualizations/histograms/sentData.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(jsonDf.to_dict('records'), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57e58b-8b1a-4cdb-bd5f-a50755ae7200",
   "metadata": {},
   "source": [
    "## Reading scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c1ff66-04cb-468f-9848-1dd633934fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a126848-8a3f-4d11-aecf-6b19dae3dabd",
   "metadata": {},
   "source": [
    "## Create Topic Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afdd8727-c9bb-4a93-8c2b-50c49d9b248f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicID</th>\n",
       "      <th>Topic Keywords</th>\n",
       "      <th>Topic Summary</th>\n",
       "      <th>Western Count</th>\n",
       "      <th>Russian Count</th>\n",
       "      <th>MoscowTimes Count</th>\n",
       "      <th>Total Count</th>\n",
       "      <th>Freq in Western</th>\n",
       "      <th>Freq in Russian</th>\n",
       "      <th>Freq in MoscowTimes</th>\n",
       "      <th>Total Freq</th>\n",
       "      <th>Western Senti Avg</th>\n",
       "      <th>Russian Senti Avg</th>\n",
       "      <th>MoscowTimes Senti Avg</th>\n",
       "      <th>Average Senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9799</td>\n",
       "      <td>11574</td>\n",
       "      <td>1313</td>\n",
       "      <td>22686</td>\n",
       "      <td>0.442393</td>\n",
       "      <td>0.413830</td>\n",
       "      <td>0.406376</td>\n",
       "      <td>0.401188</td>\n",
       "      <td>-0.010843</td>\n",
       "      <td>-0.004378</td>\n",
       "      <td>-0.100167</td>\n",
       "      <td>-0.007394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>777</td>\n",
       "      <td>1318</td>\n",
       "      <td>180</td>\n",
       "      <td>2275</td>\n",
       "      <td>0.035079</td>\n",
       "      <td>0.047125</td>\n",
       "      <td>0.055710</td>\n",
       "      <td>0.040232</td>\n",
       "      <td>-0.019656</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>194</td>\n",
       "      <td>427</td>\n",
       "      <td>24</td>\n",
       "      <td>645</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.007428</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>-0.038515</td>\n",
       "      <td>-0.005012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>176</td>\n",
       "      <td>1310</td>\n",
       "      <td>87</td>\n",
       "      <td>1573</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.046839</td>\n",
       "      <td>0.026927</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>-0.027409</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>470</td>\n",
       "      <td>622</td>\n",
       "      <td>59</td>\n",
       "      <td>1151</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.022240</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>-0.011215</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2664</td>\n",
       "      <td>2885</td>\n",
       "      <td>277</td>\n",
       "      <td>5826</td>\n",
       "      <td>0.120271</td>\n",
       "      <td>0.103154</td>\n",
       "      <td>0.085732</td>\n",
       "      <td>0.103029</td>\n",
       "      <td>-0.014428</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>-0.011339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TopicID Topic Keywords Topic Summary  Western Count  Russian Count  \\\n",
       "0        -1                                        9799          11574   \n",
       "6         5                                         777           1318   \n",
       "10        9                                         194            427   \n",
       "11       10                                         176           1310   \n",
       "3         2                                         470            622   \n",
       "15       14                                        2664           2885   \n",
       "\n",
       "    MoscowTimes Count  Total Count  Freq in Western  Freq in Russian  \\\n",
       "0                1313        22686         0.442393         0.413830   \n",
       "6                 180         2275         0.035079         0.047125   \n",
       "10                 24          645         0.008758         0.015267   \n",
       "11                 87         1573         0.007946         0.046839   \n",
       "3                  59         1151         0.021219         0.022240   \n",
       "15                277         5826         0.120271         0.103154   \n",
       "\n",
       "    Freq in MoscowTimes  Total Freq  Western Senti Avg  Russian Senti Avg  \\\n",
       "0              0.406376    0.401188          -0.010843          -0.004378   \n",
       "6              0.055710    0.040232          -0.019656          -0.012105   \n",
       "10             0.007428    0.011406          -0.038515          -0.005012   \n",
       "11             0.026927    0.027818          -0.027409          -0.004763   \n",
       "3              0.018261    0.020355          -0.011215          -0.008264   \n",
       "15             0.085732    0.103029          -0.014428          -0.008685   \n",
       "\n",
       "    MoscowTimes Senti Avg  Average Senti  \n",
       "0               -0.100167      -0.007394  \n",
       "6                     NaN      -0.014905  \n",
       "10                    NaN      -0.015478  \n",
       "11                    NaN      -0.007445  \n",
       "3                     NaN      -0.009534  \n",
       "15               0.084500      -0.011339  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TopicID\tTopic Keywords\tTopic Summary\tWestern Count\tWestern Freq\tRussian Count\tRussian Freq\tMoscowTimes Count\tMoscowTimes Freq\tTotal Count\n",
    "numTopics = 15\n",
    "topicIDs = range(-1,numTopics)\n",
    "topicStatData = []\n",
    "for topicID in topicIDs:\n",
    "    topicRec = dict()\n",
    "    topicRec['TopicID'] = topicID\n",
    "    topicRec['Topic Keywords'] = ''\n",
    "    topicRec['Topic Summary'] = ''\n",
    "    \n",
    "    wdf = df[df['category']=='western']\n",
    "    rdf = df[df['category']=='russian']\n",
    "    mtdf = df[df['category']=='moscowtimes']\n",
    "    \n",
    "    thiswdf = wdf[wdf['sentTopicID']==topicID]\n",
    "    thisrdf = rdf[rdf['sentTopicID']==topicID]\n",
    "    thismtdf = mtdf[mtdf['sentTopicID']==topicID]\n",
    "  \n",
    "    topicRec['Western Count'] = len(wdf[wdf['sentTopicID']==topicID])\n",
    "    topicRec['Russian Count'] = len(rdf[rdf['sentTopicID']==topicID])\n",
    "    topicRec['MoscowTimes Count'] = len(mtdf[mtdf['sentTopicID']==topicID])\n",
    "    topicRec['Total Count'] = len(df[df['sentTopicID']==topicID])\n",
    "    \n",
    "    topicRec['Freq in Western'] = topicRec['Western Count'] / len(wdf)\n",
    "    topicRec['Freq in Russian'] = topicRec['Russian Count'] / len(rdf)\n",
    "    topicRec['Freq in MoscowTimes'] = topicRec['MoscowTimes Count'] / len(mtdf)\n",
    "    topicRec['Total Freq'] = len(df[df['sentTopicID']==topicID])/len(df)\n",
    "    \n",
    "    topicRec['Western Senti Avg'] = thiswdf['pos'].mean()- thiswdf['neg'].mean()\n",
    "    topicRec['Russian Senti Avg'] = thisrdf['pos'].mean() - thisrdf['neg'].mean()\n",
    "    topicRec['MoscowTimes Senti Avg'] = thismtdf['pos'].mean()- thismtdf['neg'].mean()\n",
    "    topicRec['Average Senti'] = df[df['sentTopicID']==topicID]['pos'].mean() - df[df['sentTopicID']==topicID]['neg'].mean()\n",
    "    \n",
    "    topicStatData.append(topicRec)\n",
    "    \n",
    "topicStats = pd.DataFrame.from_records(topicStatData)\n",
    "topicStats.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b7952e9-54a6-45cd-9b0a-4fccd9e4c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicStats.to_excel('data/topic_model_data/topics_and_sentiment_8-3.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef492a-8d72-4c81-935f-45d05a88717c",
   "metadata": {},
   "source": [
    "### Topic Timeline Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2d30fda-b7d1-4287-bb8f-82e30c66a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a7a7029-4d6f-484a-889a-202bfa8d4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.7 s, sys: 244 ms, total: 5.95 s\n",
      "Wall time: 7.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "totalNumTopics= 15\n",
    "timeTuples = [\n",
    "    (\"2021-10-01\", \"2021-10-15\"), \n",
    "    (\"2021-10-16\", \"2021-10-31\"), \n",
    "    (\"2021-11-01\", \"2021-11-15\"), \n",
    "    (\"2021-11-16\", \"2021-11-30\"), \n",
    "    (\"2021-12-01\", \"2021-12-15\"), \n",
    "    (\"2021-12-16\", \"2021-12-31\"),    \n",
    "    (\"2022-01-01\", \"2022-01-15\"),    \n",
    "    (\"2022-01-16\", \"2022-01-31\"),\n",
    "    (\"2022-02-01\", \"2022-02-15\"),\n",
    "    (\"2022-02-16\", \"2022-02-28\"),]\n",
    "\n",
    "records = df.to_dict('records')\n",
    "\n",
    "biweeklyDict = dict()\n",
    "recCatCounts = dict()\n",
    "for rec in records:\n",
    "    if rec['category'] in ['western','russian']:\n",
    "        # add rec to timerange dict\n",
    "        for i, (startStr, endStr) in enumerate(timeTuples):\n",
    "            startDate = datetime.strptime(startStr, '%Y-%m-%d')\n",
    "            endDate = datetime.strptime(endStr, '%Y-%m-%d')\n",
    "            if rec['dateSeen'] >= startDate and rec['dateSeen'] <= endDate:\n",
    "                biweeklyDict.setdefault(i, dict())\n",
    "                for topicID in range(-1,totalNumTopics):\n",
    "                    biweeklyDict[i].setdefault(topicID, [])\n",
    "                biweeklyDict[i][rec['sentTopicID']].append(rec)\n",
    "                recCatCounts.setdefault(i, {'western' : 0,'russian' : 0})\n",
    "                recCatCounts[i][rec['category']]+= 1\n",
    "jsonForTimeline = []\n",
    "for i in biweeklyDict:\n",
    "    row = dict()\n",
    "    row['date'] = timeTuples[i][0].replace('-','')\n",
    "    row[f'western_ct_period_{i}'] = recCatCounts[i]['western']\n",
    "    row[f'russian_ct_period_{i}'] = recCatCounts[i]['russian']\n",
    "    for topicID in range(-1,totalNumTopics):\n",
    "        row['russian_freq_topic_'+str(topicID)] = len([r for r in biweeklyDict[i][topicID] if r['category']=='russian'])/recCatCounts[i]['russian']\n",
    "        row['total_freq_topic_'+str(topicID)] = len(biweeklyDict[i][topicID])/(recCatCounts[i]['russian']+recCatCounts[i]['western'])\n",
    "        row['western_freq_topic_'+str(topicID)] = len([r for r in biweeklyDict[i][topicID] if r['category']=='western'])/recCatCounts[i]['western']\n",
    "        row['russian_topic_'+str(topicID)] = len([r for r in biweeklyDict[i][topicID] if r['category']=='russian'])\n",
    "        row['western_topic_'+str(topicID)] = len([r for r in biweeklyDict[i][topicID] if r['category']=='western'])\n",
    "        row['total_topic_'+str(topicID)] = len(biweeklyDict[i][topicID])\n",
    "    jsonForTimeline.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca29b629-de9b-444e-82aa-9db3ffc6a3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '20220116',\n",
       " 'western_ct_period_7': 3805,\n",
       " 'russian_ct_period_7': 4640,\n",
       " 'russian_freq_topic_-1': 0.40323275862068964,\n",
       " 'total_freq_topic_-1': 0.41420959147424513,\n",
       " 'western_freq_topic_-1': 0.42759526938239156,\n",
       " 'russian_topic_-1': 1871,\n",
       " 'western_topic_-1': 1627,\n",
       " 'total_topic_-1': 3498,\n",
       " 'russian_freq_topic_0': 0.039439655172413796,\n",
       " 'total_freq_topic_0': 0.04227353463587922,\n",
       " 'western_freq_topic_0': 0.04572930354796321,\n",
       " 'russian_topic_0': 183,\n",
       " 'western_topic_0': 174,\n",
       " 'total_topic_0': 357,\n",
       " 'russian_freq_topic_1': 0.017456896551724138,\n",
       " 'total_freq_topic_1': 0.01705150976909414,\n",
       " 'western_freq_topic_1': 0.016557161629434953,\n",
       " 'russian_topic_1': 81,\n",
       " 'western_topic_1': 63,\n",
       " 'total_topic_1': 144,\n",
       " 'russian_freq_topic_2': 0.026077586206896552,\n",
       " 'total_freq_topic_2': 0.023564239194789817,\n",
       " 'western_freq_topic_2': 0.02049934296977661,\n",
       " 'russian_topic_2': 121,\n",
       " 'western_topic_2': 78,\n",
       " 'total_topic_2': 199,\n",
       " 'russian_freq_topic_3': 0.008405172413793103,\n",
       " 'total_freq_topic_3': 0.006867969212551806,\n",
       " 'western_freq_topic_3': 0.004993429697766097,\n",
       " 'russian_topic_3': 39,\n",
       " 'western_topic_3': 19,\n",
       " 'total_topic_3': 58,\n",
       " 'russian_freq_topic_4': 0.010991379310344827,\n",
       " 'total_freq_topic_4': 0.02048549437537004,\n",
       " 'western_freq_topic_4': 0.032063074901445464,\n",
       " 'russian_topic_4': 51,\n",
       " 'western_topic_4': 122,\n",
       " 'total_topic_4': 173,\n",
       " 'russian_freq_topic_5': 0.05603448275862069,\n",
       " 'total_freq_topic_5': 0.05281231497927768,\n",
       " 'western_freq_topic_5': 0.048883048620236534,\n",
       " 'russian_topic_5': 260,\n",
       " 'western_topic_5': 186,\n",
       " 'total_topic_5': 446,\n",
       " 'russian_freq_topic_6': 0.023060344827586208,\n",
       " 'total_freq_topic_6': 0.029484902309058616,\n",
       " 'western_freq_topic_6': 0.03731931668856767,\n",
       " 'russian_topic_6': 107,\n",
       " 'western_topic_6': 142,\n",
       " 'total_topic_6': 249,\n",
       " 'russian_freq_topic_7': 0.03577586206896552,\n",
       " 'total_freq_topic_7': 0.04322084073416223,\n",
       " 'western_freq_topic_7': 0.05229960578186597,\n",
       " 'russian_topic_7': 166,\n",
       " 'western_topic_7': 199,\n",
       " 'total_topic_7': 365,\n",
       " 'russian_freq_topic_8': 0.025,\n",
       " 'total_freq_topic_8': 0.027471876850207223,\n",
       " 'western_freq_topic_8': 0.030486202365308804,\n",
       " 'russian_topic_8': 116,\n",
       " 'western_topic_8': 116,\n",
       " 'total_topic_8': 232,\n",
       " 'russian_freq_topic_9': 0.023060344827586208,\n",
       " 'total_freq_topic_9': 0.017643576080521018,\n",
       " 'western_freq_topic_9': 0.011038107752956636,\n",
       " 'russian_topic_9': 107,\n",
       " 'western_topic_9': 42,\n",
       " 'total_topic_9': 149,\n",
       " 'russian_freq_topic_10': 0.026077586206896552,\n",
       " 'total_freq_topic_10': 0.015985790408525755,\n",
       " 'western_freq_topic_10': 0.0036793692509855453,\n",
       " 'russian_topic_10': 121,\n",
       " 'western_topic_10': 14,\n",
       " 'total_topic_10': 135,\n",
       " 'russian_freq_topic_11': 0.0010775862068965517,\n",
       " 'total_freq_topic_11': 0.002605091770278271,\n",
       " 'western_freq_topic_11': 0.004467805519053876,\n",
       " 'russian_topic_11': 5,\n",
       " 'western_topic_11': 17,\n",
       " 'total_topic_11': 22,\n",
       " 'russian_freq_topic_12': 0.0665948275862069,\n",
       " 'total_freq_topic_12': 0.06939017169923031,\n",
       " 'western_freq_topic_12': 0.07279894875164257,\n",
       " 'russian_topic_12': 309,\n",
       " 'western_topic_12': 277,\n",
       " 'total_topic_12': 586,\n",
       " 'russian_freq_topic_13': 0.1459051724137931,\n",
       " 'total_freq_topic_13': 0.12338661930136176,\n",
       " 'western_freq_topic_13': 0.09592641261498029,\n",
       " 'russian_topic_13': 677,\n",
       " 'western_topic_13': 365,\n",
       " 'total_topic_13': 1042,\n",
       " 'russian_freq_topic_14': 0.09181034482758621,\n",
       " 'total_freq_topic_14': 0.09354647720544701,\n",
       " 'western_freq_topic_14': 0.09566360052562418,\n",
       " 'russian_topic_14': 426,\n",
       " 'western_topic_14': 364,\n",
       " 'total_topic_14': 790}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(jsonForTimeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbecbb89-8387-4450-adee-fd66b7355bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('visualizations/timeline/freq_data_8-3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(jsonForTimeline, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab81e4-f1b4-459f-8827-7e835e76aaf6",
   "metadata": {},
   "source": [
    "## Co-occurrence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26518663-acce-4d5e-ac0e-28742accfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76db2db3-3b9d-4844-8678-9d00a45bdd74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740881b8feaa454992458d2924bacc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 20:37:31 INFO: Downloading default packages for language: en (English)...\n",
      "2022-08-03 20:37:33 INFO: File exists: /Users/paigelee/stanza_resources/en/default.zip.\n",
      "2022-08-03 20:37:37 INFO: Finished downloading models and saved to /Users/paigelee/stanza_resources.\n",
      "2022-08-03 20:37:37 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-08-03 20:37:37 INFO: Use device: cpu\n",
      "2022-08-03 20:37:37 INFO: Loading: tokenize\n",
      "2022-08-03 20:37:38 INFO: Loading: pos\n",
      "2022-08-03 20:37:41 INFO: Loading: lemma\n",
      "2022-08-03 20:37:41 INFO: Loading: depparse\n",
      "2022-08-03 20:37:42 INFO: Loading: sentiment\n",
      "2022-08-03 20:37:43 INFO: Loading: ner\n",
      "2022-08-03 20:37:45 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8baee06e-cd7b-4b58-b371-dc89f65fe269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "engStopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ec5c116-925e-4639-9cbc-e2417e256aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60827ca2-26be-4ab9-9bab-747154990d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/16394 recs parsed by NLP\n",
      "1000/16394 recs parsed by NLP\n",
      "2000/16394 recs parsed by NLP\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get cooccurrence connections\n",
    "thresh = 5\n",
    "n = 4\n",
    "\n",
    "allSentRecords = sdf.to_dict('records')\n",
    "\n",
    "for cat in ['russian']:\n",
    "    networkJson = dict()\n",
    "    networkJson['nodes'] = []\n",
    "    networkJson['links'] = []\n",
    "\n",
    "    curatedNodes = set()\n",
    "    linkCounter = dict()\n",
    "    keywordCounter = dict()\n",
    "\n",
    "    windowList = []\n",
    "    records = []\n",
    "    for d in allSentRecords:\n",
    "        if d['category'] == cat and d['sentTopicID'] != -1:\n",
    "            records.append(d)\n",
    "    for i, rec in enumerate(records):\n",
    "        if i % 1000 == 0:\n",
    "            print(f'{i}/{len(records)} recs parsed by NLP')\n",
    "        docText = rec['sentText']\n",
    "        nlpdoc = nlp(docText)\n",
    "        wordList = [w for w in nlpdoc.iter_words() if w.text.isalpha() and w.text.lower() not in engStopwords]\n",
    "        for windowIdx in range(len(wordList) // n + len(wordList) % n):\n",
    "            startIdx = windowIdx\n",
    "            endIdx = windowIdx+random.choice(list(range(1,n+1)))\n",
    "            wordWindow = wordList[startIdx:endIdx]\n",
    "            tokens = []\n",
    "            for wordToken in wordWindow:\n",
    "                formattedToken = wordToken.lemma.lower()\n",
    "                if formattedToken in engStopwords:\n",
    "                    continue\n",
    "                tokens.append(formattedToken)\n",
    "            windowList.append(tokens)\n",
    "        for t1 in [w.lemma.lower() for w in wordList]:\n",
    "            keywordCounter.setdefault(t1, 0)\n",
    "            keywordCounter[t1] += 1\n",
    "    print('\\tdone nlping docs')\n",
    "    sufficientNodes = set()\n",
    "    for key in keywordCounter:\n",
    "        if keywordCounter[key] >= thresh:\n",
    "            sufficientNodes.add(key)\n",
    "    print('\\tfound sufficient recs')\n",
    "    for tokens in windowList:\n",
    "        s = set(tokens)\n",
    "        subsets = [tuple(i) for i in itertools.combinations(s, 2)]\n",
    "        for t1, t2 in subsets:\n",
    "            if t1 != t2 and t1 in sufficientNodes and t2 in sufficientNodes:\n",
    "                label = '_'.join(sorted([t1, t2]))\n",
    "                linkCounter.setdefault(label, 0)\n",
    "                linkCounter[label] += 1\n",
    "    print('\\tgot linked tokens')\n",
    "    node2id = dict()\n",
    "    for i, node in enumerate(sufficientNodes):\n",
    "        networkJson['nodes'].append({\n",
    "            'id' : node,\n",
    "            'occurrences' : keywordCounter[node]\n",
    "        })\n",
    "        node2id[node] = i\n",
    "\n",
    "    for label in linkCounter:\n",
    "        source, target = label.split('_')\n",
    "        networkJson['links'].append({\n",
    "            'source' : node2id[source],\n",
    "            'target' : node2id[target],\n",
    "            'value' : linkCounter[label]\n",
    "        })\n",
    "    \n",
    "    jsonDict[cat] = networkJson\n",
    "    \n",
    "    with open(f'visualizations/ngramsNetwork/{cat}ngramNet{n}_8-4.json', 'w', encoding ='ascii') as json_file:\n",
    "        json.dump(networkJson, json_file, ensure_ascii = True)\n",
    "    print('\\twrote json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea33c8-6230-4c80-8101-cad1f00f9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56b565e9-c05c-4b82-9e3c-e1a9df20f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'visualizations/ngramsNetwork/{cat}ngramNet{n}_8-4.json', 'w', encoding ='ascii') as json_file:\n",
    "    json.dump(networkJson, json_file, ensure_ascii = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c9127-0eb8-4029-bd9d-a44fec5e37db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5ee8cb8-7047-4b2e-a9c6-f5c79ab4de31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/topic model data/topicArticleFrame7-31.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jj/_szc94p56q91q_7c209d1d9w0000gn/T/ipykernel_3197/1802861011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/topic model data/topicArticleFrame7-31.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/topic model data/topicArticleFrame7-31.xlsx'"
     ]
    }
   ],
   "source": [
    "# df = pd.read_excel('data/topic model data/topicArticleFrame7-31.xlsx',index_col=0)\n",
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00b41e-4b5b-4b0f-a026-4c2fe6d76c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TopicID</th>\n",
       "      <th>Topic Keywords</th>\n",
       "      <th>Topic Summary</th>\n",
       "      <th>Western Count</th>\n",
       "      <th>Freq in Western</th>\n",
       "      <th>Russian Count</th>\n",
       "      <th>Freq in Russian</th>\n",
       "      <th>MoscowTimes Count</th>\n",
       "      <th>Freq in MoscowTimes</th>\n",
       "      <th>Total Count</th>\n",
       "      <th>Total Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>469</td>\n",
       "      <td>0.018757</td>\n",
       "      <td>674</td>\n",
       "      <td>0.022437</td>\n",
       "      <td>22</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>1165</td>\n",
       "      <td>0.019971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>792</td>\n",
       "      <td>0.031675</td>\n",
       "      <td>1289</td>\n",
       "      <td>0.042911</td>\n",
       "      <td>148</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>2229</td>\n",
       "      <td>0.038210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>138</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>629</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>56</td>\n",
       "      <td>0.017006</td>\n",
       "      <td>823</td>\n",
       "      <td>0.014108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>268</td>\n",
       "      <td>0.010718</td>\n",
       "      <td>353</td>\n",
       "      <td>0.011751</td>\n",
       "      <td>148</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>769</td>\n",
       "      <td>0.013182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>842</td>\n",
       "      <td>0.033675</td>\n",
       "      <td>699</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>90</td>\n",
       "      <td>0.027331</td>\n",
       "      <td>1631</td>\n",
       "      <td>0.027959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>375</td>\n",
       "      <td>0.014998</td>\n",
       "      <td>79</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>49</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>503</td>\n",
       "      <td>0.008622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TopicID Topic Keywords Topic Summary  Western Count  Freq in Western  \\\n",
       "20       19                                         469         0.018757   \n",
       "13       12                                         792         0.031675   \n",
       "11       10                                         138         0.005519   \n",
       "15       14                                         268         0.010718   \n",
       "18       17                                         842         0.033675   \n",
       "17       16                                         375         0.014998   \n",
       "\n",
       "    Russian Count  Freq in Russian  MoscowTimes Count  Freq in MoscowTimes  \\\n",
       "20            674         0.022437                 22             0.006681   \n",
       "13           1289         0.042911                148             0.044944   \n",
       "11            629         0.020939                 56             0.017006   \n",
       "15            353         0.011751                148             0.044944   \n",
       "18            699         0.023270                 90             0.027331   \n",
       "17             79         0.002630                 49             0.014880   \n",
       "\n",
       "    Total Count  Total Freq  \n",
       "20         1165    0.019971  \n",
       "13         2229    0.038210  \n",
       "11          823    0.014108  \n",
       "15          769    0.013182  \n",
       "18         1631    0.027959  \n",
       "17          503    0.008622  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TopicID\tTopic Keywords\tTopic Summary\tWestern Count\tWestern Freq\tRussian Count\tRussian Freq\tMoscowTimes Count\tMoscowTimes Freq\tTotal Count\n",
    "topicCols = [col for col in df.columns if 'topic' in col]\n",
    "topicStatData = []\n",
    "for topicCol in topicCols:\n",
    "    topicRec = dict()\n",
    "    topicRec['TopicID'] = int(topicCol.split('_')[1])\n",
    "    topicRec['Topic Keywords'] = ''\n",
    "    topicRec['Topic Summary'] = ''\n",
    "    \n",
    "    topicRec['Western Count'] = df[df['category']=='western'][topicCol].sum()\n",
    "    topicRec['Freq in Western'] = df[df['category']=='western'][topicCol].sum()/df[df['category']=='western']['sentsInArticle'].sum()\n",
    "    \n",
    "    topicRec['Russian Count'] = df[df['category']=='russian'][topicCol].sum()\n",
    "    topicRec['Freq in Russian'] = df[df['category']=='russian'][topicCol].sum()/df[df['category']=='russian']['sentsInArticle'].sum()\n",
    "    \n",
    "    topicRec['MoscowTimes Count'] = df[df['category']=='moscowtimes'][topicCol].sum()\n",
    "    topicRec['Freq in MoscowTimes'] = df[df['category']=='moscowtimes'][topicCol].sum()/df[df['category']=='moscowtimes']['sentsInArticle'].sum()\n",
    "    \n",
    "    topicRec['Total Count'] = df[topicCol].sum()\n",
    "    topicRec['Total Freq'] = df[topicCol].sum()/df['sentsInArticle'].sum()\n",
    "    topicStatData.append(topicRec)\n",
    "    \n",
    "topicStats = pd.DataFrame.from_records(topicStatData)\n",
    "topicStats.sample(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
